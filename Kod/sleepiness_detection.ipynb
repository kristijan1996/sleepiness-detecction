{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new person to database\n",
    "\n",
    "Take pictures of people which are supposed to have access to the system, and save them in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import cvlib\n",
    "\n",
    "# Number of photos to take of each person\n",
    "# More photos = more reliable embedding vector estimation\n",
    "NUM_OF_PHOTOS = 50\n",
    "\n",
    "# Path to folder in which photos are stored\n",
    "IMAGES_PATH = 'face_images'\n",
    "\n",
    "# Create directory for storing face images\n",
    "# if it does not exist yet\n",
    "try:\n",
    "    os.mkdir(IMAGES_PATH)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "\n",
    "def take_pictures(persons_name):\n",
    "    \"\"\"\n",
    "    Captures face photos by using camera\n",
    "    and stores them in folder\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    pesons_name - string containing name of the\n",
    "                  person pictures will be taken of\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a subdirectory to store photos for each person\n",
    "        dir_name = os.path.join(IMAGES_PATH, persons_name)\n",
    "        try:\n",
    "            os.mkdir(dir_name)\n",
    "        except FileExistsError:\n",
    "            # This means we already have photos of that person\n",
    "            print('{} already exists in database!'.format(persons_name))\n",
    "            return\n",
    "        \n",
    "        # Instanciate capture object in order to\n",
    "        # gain access to camera\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # Some aux flags used to count photos taken and start\n",
    "        # of the process\n",
    "        start = False\n",
    "        photo_count = 0\n",
    "\n",
    "        # Take NUM_OF_PHOTOS shots\n",
    "        while photo_count != NUM_OF_PHOTOS:\n",
    "            # Capture a frame from camera\n",
    "            ret, frame = cap.read()\n",
    "            # If reading was successful, continue\n",
    "            # processing. If not, try again\n",
    "            if not ret:\n",
    "                print('Problem connecting to camera!')\n",
    "                continue\n",
    "\n",
    "            # Detect faces in the photo using cvlib\n",
    "            # Algorithm will detect face closest to\n",
    "            # camera with highest probability, but it\n",
    "            # might also detect other faces around it, \n",
    "            # but in face recognition use case only one \n",
    "            # face is expected in front of camera anyway\n",
    "            faces, _ = cvlib.detect_face(frame)\n",
    "\n",
    "            # If at least one face was detected\n",
    "            if len(faces) != 0:\n",
    "                # Mark coordinates of the rectangle surrounding face\n",
    "                (startX, startY) = faces[0][0], faces[0][1]\n",
    "                (endX, endY) = faces[0][2], faces[0][3]\n",
    "\n",
    "                # Draw white rectangle over face\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY), (0,255,0), 2)\n",
    "\n",
    "                # If 's' was pressed, the capturing has started\n",
    "                if start:\n",
    "                    # Extract only region surrounded by box\n",
    "                    roi = frame[startY+2:endY-2, startX+2:endX-2]\n",
    "                    # resize it to (160,160,3), as expected by NN model\n",
    "                    resized = cv2.resize(roi, (160,160), interpolation = cv2.INTER_AREA)\n",
    "                    # and save it to disc\n",
    "                    save_path = os.path.join(dir_name, '{}.jpg'.format(photo_count + 1))\n",
    "                    cv2.imwrite(save_path, resized)\n",
    "                    photo_count += 1\n",
    "\n",
    "            # Put some indicator text above image and display what camera sees\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame, \"{}, please look straight in the camera\".format(persons_name),\n",
    "                        (5, 30), font, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, \"Collecting {}. photo\".format(photo_count),\n",
    "                        (5, 50), font, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            # Display what is currently captured by camera along with above text\n",
    "            cv2.imshow(\"Collecting images of {}\".format(persons_name), frame)\n",
    "\n",
    "            # Listen for key presses\n",
    "            k = cv2.waitKey(1)\n",
    "            if k == ord('s'):\n",
    "                start = True\n",
    "\n",
    "            if k == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Print output text indicating that photo shooting is finished\n",
    "        print(\"\\n{} image(s) saved to {}\".format(photo_count, dir_name))\n",
    "\n",
    "        # Release the camera\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new person to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = 'Kristijan'\n",
    "\n",
    "#take_pictures(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make face embeddings out of pictures\n",
    "\n",
    "When images for people we want to have access to the\n",
    "system are collected, we proceed to make embedding\n",
    "vectors of them, average them and estimate the largest\n",
    "Euclidian distance up to which we can consider faces\n",
    "to belong to the same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_1:0' shape=(None, 160, 160, 3) dtype=float32>]\n",
      "[<tf.Tensor 'Bottleneck_BatchNorm/cond/Identity:0' shape=(None, 128) dtype=float32>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kris\\anaconda3\\envs\\tf_keras\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Path to folder where photos were stored\n",
    "IMAGES_PATH = 'face_images'\n",
    "\n",
    "# Path to folder where npy files are stored\n",
    "# for each person, containing their averaged embedding\n",
    "# vector and maximum deviation from that vector\n",
    "EMBEDDINGS_PATH = 'embeddings'\n",
    "\n",
    "# Create directory for storing embeddings\n",
    "# if it does not exist yet\n",
    "try:\n",
    "    os.mkdir(EMBEDDINGS_PATH)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Load the model\n",
    "model = load_model('pretrained_models/facenet_keras.h5')\n",
    "\n",
    "# Summarize input and output shape\n",
    "print(model.inputs)\n",
    "print(model.outputs)\n",
    "\n",
    "def create_embeddings(persons_name):\n",
    "    \"\"\"\n",
    "    Images of person are passed through pretrained NN\n",
    "    to produce 128 dimensional embedding vector for \n",
    "    each image, which are then averaged to obtain one\n",
    "    vector to represent that person, which is then\n",
    "    stored in .npy file\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    persons_name - string containing name of the person\n",
    "    \"\"\"\n",
    "    emb_file = EMBEDDINGS_PATH + '/' + persons_name + '.npy'\n",
    "    if os.path.exists(emb_file):\n",
    "        print('Embeddings for {} already exist!'.format(persons_name))\n",
    "        return\n",
    "    \n",
    "    path_to_photos = IMAGES_PATH + '/' + persons_name\n",
    "    images = os.listdir(path_to_photos)\n",
    "    embeddings = []\n",
    "    \n",
    "    for photo in images:\n",
    "        face = cv2.imread(path_to_photos + '/' + photo).astype('float32')\n",
    "        # standardize pixel values across channels (global)\n",
    "        mean, std = face.mean(), face.std()\n",
    "        face = (face - mean) / std\n",
    "        # transform face into one sample\n",
    "        sample = np.expand_dims(face, axis=0)\n",
    "        \n",
    "        # Form a 128 dimensional vector representing image\n",
    "        # by passing image through the model\n",
    "        embedding = model.predict(sample)[0]\n",
    "        # and store it for person\n",
    "        embeddings.append(embedding)\n",
    "        \n",
    "    embeddings = np.asarray(embeddings) # shape is (num_of_photos, 128)\n",
    "    # Average all embedding vectors to obtain one vector\n",
    "    # representing person and normalize it\n",
    "    mean = normalize(np.mean(embeddings, axis=0).reshape(1,128), axis=1)\n",
    "    \n",
    "    emb_dict = {\n",
    "        'name' : persons_name,\n",
    "        'emb_vec' : mean\n",
    "    }\n",
    "    np.save(emb_file, emb_dict)\n",
    "    \n",
    "    print('Embeddings for {} created!'.format(persons_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create embeddings for all familiar people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#familiar_people = os.listdir(IMAGES_PATH)\n",
    "\n",
    "#for person in familiar_people:\n",
    "#    create_embeddings(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the system\n",
    "\n",
    "Situation: someone is trying to gain access to the system. We check if their\n",
    "embedding matches any of familiar ones, and based on that allow them or deny\n",
    "access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import cvlib\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('pretrained_models/facenet_keras.h5')\n",
    "\n",
    "# Path to folder where npy files are stored\n",
    "# for each person, containing their averaged embedding\n",
    "# vector and maximum deviation from that vector\n",
    "EMBEDDINGS_PATH = 'embeddings'\n",
    "\n",
    "# Recognition timeout in secs\n",
    "TIMEOUT = 5\n",
    "\n",
    "# Similarity Euclidian distance. If embedding vectors\n",
    "# are farther away that this, face is considered to be\n",
    "# of different person\n",
    "SIMILARITY_THRESH = 0.7\n",
    "\n",
    "# Font used for opencv\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "def detect_face(frame):\n",
    "    \"\"\"\n",
    "    Detect faces using cvlib, if there are any in the frame.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    frame - frame captured by openCV\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    boolean showning whether a face was detected,\n",
    "    isolated pixels containing only face if one was detected,\n",
    "    list containing two opposite corners of rectangle containing\n",
    "    face\n",
    "    \"\"\"\n",
    "    # Detect face in the frame\n",
    "    faces, _ = cvlib.detect_face(frame)\n",
    "    \n",
    "    # If at least one face was detected\n",
    "    if len(faces) != 0:\n",
    "        # Mark coordinates of the rectangle surrounding face\n",
    "        (startX, startY) = faces[0][0], faces[0][1]\n",
    "        (endX, endY) = faces[0][2], faces[0][3]\n",
    "\n",
    "        # Extract only region surrounded by box\n",
    "        roi = frame[startY+2:endY-2, startX+2:endX-2]\n",
    "        # resize it to (160,160,3), as expected by NN model\n",
    "        face = cv2.resize(roi, (160,160), interpolation = cv2.INTER_AREA).astype('float32')\n",
    "        \n",
    "        # standardize pixel values across channels \n",
    "        mean, std = face.mean(), face.std()\n",
    "        face = (face - mean) / std\n",
    "                \n",
    "        return True, face, [startX, startY, endX, endY]\n",
    "    \n",
    "    else:\n",
    "        return False, None, None\n",
    "\n",
    "    \n",
    "def recognize_face(face, known_emb):\n",
    "    \"\"\"\n",
    "    Compares embedding vector of a face passed as\n",
    "    argument to vectors of people to which access\n",
    "    is allowed, stored previously on disc\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    face - (160,160,3) shaped ndarray containing only a face\n",
    "            which is to be compared to stored faces\n",
    "                \n",
    "    Returns\n",
    "    -------\n",
    "    boolean showing whether passed face was recognized,\n",
    "    name of the person, if face was recongized\n",
    "    \"\"\"\n",
    "    # Form a normalized 128 dimensional vector representing image\n",
    "    # by passing image through the model\n",
    "    embedding = normalize(model.predict(np.expand_dims(face, axis=0))[0].reshape(1,128), axis=1)\n",
    "            \n",
    "    for person in known_emb:\n",
    "        emb = person['emb_vec']\n",
    "        # Find L2 distance between newcomers face and a familiar one\n",
    "        diff = np.linalg.norm(emb - embedding, axis=1)\n",
    "        print('Distance: ', diff)\n",
    "        # Empirical threshold large enough to distinct faces\n",
    "        if diff < SIMILARITY_THRESH:\n",
    "            return True, person['name']\n",
    "        \n",
    "    return False, None\n",
    "\n",
    "\n",
    "def display_frame(orig_frame, text, has_rect=False, rect=None, rect_color=(255,255,255)):\n",
    "    \"\"\"\n",
    "    Boilerplate code to display decorated frame with or without text and rectangle\n",
    "    \"\"\"\n",
    "    frame = np.copy(orig_frame)\n",
    "    cv2.putText(frame, text, (5, 30), FONT, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "    if has_rect:\n",
    "        # Draw green rectangle over face\n",
    "        cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), rect_color, 2)\n",
    "        \n",
    "    # Display what is currently captured by camera along with above text\n",
    "    cv2.imshow(\"Camera\", frame)\n",
    "    \n",
    "    \n",
    "def access():\n",
    "    \"\"\"\n",
    "    Function requesting access to the system.\n",
    "    Camera is turned on and faces are detected.\n",
    "    If no face was detected, after a 5 sec timeout,\n",
    "    system will go back to sleep.\n",
    "    If face was detected, function proceeds to try and\n",
    "    recognize it. If the face was recognized, it allows\n",
    "    access to the system. Otherwise, it denies it.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    boolean - True if acces was granted, False otherwise\n",
    "    \"\"\"\n",
    "    # Wrapped up in try-except block to properly release\n",
    "    # camera if something goes wrong\n",
    "    try:\n",
    "        # Mark the starting time, to be able to timeout\n",
    "        # requests to access the system\n",
    "        start = time.time()\n",
    "        \n",
    "        # Create list of known people's embeddings\n",
    "        known_emb = []\n",
    "        for file in os.listdir(EMBEDDINGS_PATH):\n",
    "            emb = np.load(EMBEDDINGS_PATH + '/' + file, allow_pickle=True).item()\n",
    "            known_emb.append(emb)\n",
    "        \n",
    "        # Instanciate capture object in order to\n",
    "        # gain access to camera\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # Main loop looking for faces\n",
    "        while True:\n",
    "            # Capture a frame from camera\n",
    "            ret, frame = cap.read()\n",
    "            # If reading was successful, continue\n",
    "            # processing. If not, try again\n",
    "            if not ret:\n",
    "                print('Problem connecting to camera!')\n",
    "                continue\n",
    "                \n",
    "            # Exit process midway through by pressing 'q'\n",
    "            if cv2.waitKey(10) == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return False\n",
    "\n",
    "            # Try to detect face in the frame\n",
    "            face_detected, face, rect = detect_face(frame)\n",
    "\n",
    "            if face_detected: \n",
    "                # Display white rect around the face\n",
    "                display_frame(frame, \"Please look straight in the camera\", True, rect, (255,255,255))\n",
    "\n",
    "                # Try to recognize person in the photo\n",
    "                face_recognized, person = recognize_face(face, known_emb)\n",
    "                \n",
    "                if face_recognized:\n",
    "                    # Display green rect around the face\n",
    "                    display_frame(frame, \"Welcome, {}! Press ENTER to continue\".format(person),\n",
    "                                  True, rect, (0,255,0))\n",
    "                    \n",
    "                    # Wait for recognized person to press ENTER to gain access to the system\n",
    "                    if cv2.waitKey(1) == 13:\n",
    "                        # Release the camera\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                        return True\n",
    "                    \n",
    "                # If face wasn't recognized\n",
    "                else:\n",
    "                    # After some time, if no face was recognized, stop execution\n",
    "                    if time.time() - start > TIMEOUT:\n",
    "                        print('Intruder alert! Access denied!')\n",
    "                        # Display red rect around the face\n",
    "                        display_frame(frame, \"Intruder alert! Access denied!\", True, rect, (0,0,255))\n",
    "                        \n",
    "                        # Wait for unrecognized person to press ENTER to exit\n",
    "                        if cv2.waitKey(0) == 13:\n",
    "                            # Release the camera\n",
    "                            cap.release()\n",
    "                            cv2.destroyAllWindows()\n",
    "                            return False\n",
    "                    # If timeout hasn't elapsed, try once again to recognize face\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "            # If no face was detected\n",
    "            else:\n",
    "                # Display what camera sees\n",
    "                display_frame(frame, \"Please look straight in the camera\")\n",
    "                # If q was pressed or time has expired, stop execution\n",
    "                if time.time() - start > TIMEOUT:\n",
    "                    print('No faces recognized! Access denied!')\n",
    "                    # Release the camera\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return False\n",
    "    # Handle exception\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to gain access to the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleepiness detection\n",
    "\n",
    "Constantly monitor face and calculate eye-aspect-ratio - a measure of how much the eyes are closed. If EAR goes below some empirical threshold, sound the alarm to wake driver up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import playsound\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# Define two constants, one for the eye aspect ratio to indicate\n",
    "# closed eyes and a second constant for the number of seconds\n",
    "# the EAR must be below the threshold to set off the alarm\n",
    "EAR_THRESH = 0.28\n",
    "EAR_TIMEOUT = 3\n",
    "\n",
    "# Font for opencv\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Path to wav file\n",
    "ALARM_SOUND_PATH = 'sounds/alarm.wav'\n",
    "\n",
    "# Initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('pretrained_models/shape_predictor.dat')\n",
    "\n",
    "# Grab the indexes of the facial landmarks for the left and\n",
    "# right eye, respectively\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "\n",
    "def sound_alarm(path):\n",
    "    \"\"\" Convenience function to play sound \"\"\"\n",
    "    playsound.playsound(path)\n",
    "    \n",
    "def calc_ear(eye):\n",
    "    \"\"\"\n",
    "    Function to calculate eye aspect ratio\n",
    "    \n",
    "    Eye is passed as an np array of 6 elements containing [x, y] \n",
    "    coordinates of following points\n",
    "                \n",
    "                P1      P2\n",
    "                 *      *\n",
    "                   ---\n",
    "                /       \\  \n",
    "    P0 *       (    O    )       * P3\n",
    "                \\       /\n",
    "                   ---\n",
    "                 *      *\n",
    "                P5      P4\n",
    "                 \n",
    "    Arguments\n",
    "    ---------\n",
    "    eye - np array of 6 elements containing (x, y) coordinates of above\n",
    "            described points on eye\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    EAR calculated as (dist(P1, P5) + dist(P2, P4))/(2 * dist(P0, P3))\n",
    "    \n",
    "    \"\"\"\n",
    "    # Compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "\n",
    "    # Compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "\n",
    "    # Compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "\n",
    "    return ear\n",
    "\n",
    "def monitor_driver():\n",
    "    \"\"\"\n",
    "    Wrapper function monitoring camera frames, detecting eyes and\n",
    "    calculating EAR to determine if driver has dosed off, in which\n",
    "    case it sounds an alarm. It goes on in a loop until 'q' is pressed\n",
    "    \"\"\"\n",
    "    # Initialize the frame counter as well as a boolean used to\n",
    "    # indicate if the alarm is going off\n",
    "    ALARM_ON = False\n",
    "    # Time point showing the exact moment driver fell asleep\n",
    "    start = 0\n",
    "    # Flag indicating if EAR has fallen bellow\n",
    "    FLAG = 0\n",
    "    \n",
    "    try:\n",
    "        # Instanciate capture object in order to\n",
    "        # gain access to camera\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # Main loop looking for faces\n",
    "        while True:\n",
    "            # Capture a frame from camera\n",
    "            ret, frame = cap.read()\n",
    "            # If reading was successful, continue\n",
    "            # processing. If not, try again\n",
    "            if not ret:\n",
    "                print('Problem connecting to camera!')\n",
    "                continue\n",
    "\n",
    "            # At any time pressing 'q' will close the program\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "            \n",
    "            # Turn image to bw\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect faces in the grayscale frame\n",
    "            rects = face_detector(gray, 0)\n",
    "\n",
    "            # Loop over the face detections, even though only one is expected\n",
    "            for rect in rects:\n",
    "                # Determine the facial landmarks for the face region, then\n",
    "                # convert the facial landmark (x, y)-coordinates to a np array\n",
    "                shape = predictor(gray, rect)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "                # Extract the left and right eye coordinates, then use the\n",
    "                # coordinates to compute the eye aspect ratio for both eyes\n",
    "                left_eye = shape[lStart:lEnd]\n",
    "                right_eye = shape[rStart:rEnd]\n",
    "                left_ear = calc_ear(left_eye)\n",
    "                right_ear = calc_ear(right_eye)\n",
    "                \n",
    "                # Average the eye aspect ratio together for both eyes\n",
    "                EAR = (left_ear + right_ear) / 2.0\n",
    "\n",
    "                # Compute the convex hull for the left and right eye, then\n",
    "                # visualize each of the eyes\n",
    "                left_eye_contour = cv2.convexHull(left_eye)\n",
    "                right_eye_contour = cv2.convexHull(right_eye)\n",
    "                cv2.drawContours(frame, [left_eye_contour], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(frame, [right_eye_contour], -1, (0, 255, 0), 1)\n",
    "\n",
    "                # Check to see if the eye aspect ratio is below the \n",
    "                # threshold, and if so, increment the frame counter\n",
    "                if EAR < EAR_THRESH:\n",
    "                    if FLAG == 0:\n",
    "                        FLAG = 1\n",
    "                        start = time.time()\n",
    "\n",
    "                    # If the eyes were closed for a sufficient number of frames\n",
    "                    # then sound the alarm\n",
    "                    if time.time() - start >= EAR_TIMEOUT:\n",
    "                        # If the alarm is not on, turn it on\n",
    "                        if not ALARM_ON:\n",
    "                            ALARM_ON = True\n",
    "                            # Start a thread to have the alarm\n",
    "                            # sound played in the background\n",
    "                            t = Thread(target=sound_alarm, args=(ALARM_SOUND_PATH,))\n",
    "                            t.deamon = True\n",
    "                            t.start()\n",
    "\n",
    "                        # Print text to show drowsiness was detected\n",
    "                        cv2.putText(frame, \"WAKE UP!\", (10, 30), FONT, 0.7, (0, 0, 0), 1)\n",
    "\n",
    "                # otherwise, the eye aspect ratio is not below the blink\n",
    "                # threshold, so reset the counter and alarm\n",
    "                else:\n",
    "                    FLAG = 0\n",
    "                    ALARM_ON = False\n",
    "\n",
    "                # Draw the computed eye aspect ratio on the frame to help\n",
    "                # with debugging and setting the correct eye aspect ratio\n",
    "                # thresholds and EAR_TIMEOUT\n",
    "                cv2.putText(frame, \"EAR: {:.2f}\".format(EAR), (500, 30), FONT, 0.7, (0, 0, 0), 1)\n",
    "\n",
    "            # show the frame\n",
    "            cv2.imshow(\"Camera\", frame)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monitor_driver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the complete program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"\\nMain menu:\\n1. Add new person\\n2. Monitor driver\\n\")\n",
    "\n",
    "    option = int(input(\"Choose one option \"))\n",
    "    \n",
    "    if option == 1:\n",
    "        name = input('Enter persons name: ')\n",
    "        take_pictures(name)\n",
    "        create_embeddings(name)\n",
    "        \n",
    "    elif option == 2:\n",
    "        if access():\n",
    "            monitor_driver()\n",
    "            \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
